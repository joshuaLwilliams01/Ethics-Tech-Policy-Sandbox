{
  "level": 2,
  "title": "Algorithmic Decision-Making & Fairness",
  "scenarios": [
    {
      "scenario_id": "L2-S1",
      "title": "The Screening Model",
      "prompt": "A corporation has implemented an automated hiring tool with high precision, but it still sees a 10â€“15% disparity in outcomes among different demographic groups. Balancing fairness with efficiency is challenging, as retraining the algorithm may delay hiring processes. What would you do?",
      "choices": {
        "A": "Continue to implement and include human-in-the-loop appeals.",
        "B": "Stop implementation for 6 weeks to optimize equalized odds, accepting lower throughput.",
        "C": "Hybrid approach: restrict use for roles with minimal disparity; use manual processes for others."
      },
      "toolkit_cues": "Which fairness goal are we optimizing? Who absorbs false negatives?",
      "p3_cues": "People (rejected applicants), Planet (retraining compute), Parity (opportunity gaps).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": [
          "Define fairness metrics and targets",
          "Establish appeal and review process",
          "Conduct bias audit across demographic groups"
        ],
        "metrics": [
          "Demographic parity %",
          "Appeal success rate"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Values Explainer Cards, Impact Explorer"
    },
    {
      "scenario_id": "L2-S2",
      "title": "Credit by Phone",
      "prompt": "A lender is using phone bills and location data to evaluate loan eligibility. As this practice becomes more widespread, the convenience of quick approvals comes with growing concerns about your privacy. What is your decision on this?",
      "choices": {
        "A": "Implement the system, but provide clear options for users to opt out and offer thorough explanations.",
        "B": "Encourage participation only through an opt-in model that includes independent bias audits.",
        "C": "Test the system on small loans initially and analyze the outcomes."
      },
      "toolkit_cues": "What privacy harms could arise from location scoring? What safer pilots exist?",
      "p3_cues": "People (over-indebted), Planet (always-on scoring), Parity (data-poor applicants).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": [
          "Conduct bias audit on scoring model",
          "Establish clear consent process and documentation",
          "Create appeal process for loan denials"
        ],
        "metrics": [
          "Opt-in rate %",
          "Bias audit results",
          "Appeal success rate"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Future Story, Weighing Options"
    },
    {
      "scenario_id": "L2-S3",
      "title": "Webcam Exams",
      "prompt": "A recent study shows that online proctoring systems are incorrectly flagging 'suspicious gaze' more often for dark-skinned students, raising serious concerns about fairness and accuracy in digital testing. What would you do if you needed to solve this problem?",
      "choices": {
        "A": "Continue using the system, but ensure to incorporate human checks and perform additional calibration.",
        "B": "Provide alternatives to webcams, such as oral presentations or portfolios.",
        "C": "Pause the system until the error gaps have been resolved."
      },
      "toolkit_cues": "Who is mis-flagged and with what consequences? What low-intrusion options exist?",
      "p3_cues": "People (stress/dignity), Planet (video monitoring), Parity (false positives by skin tone).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": [
          "Conduct bias audit on proctoring system",
          "Develop alternative assessment methods",
          "Establish clear appeal process for flagged exams"
        ],
        "metrics": [
          "False positive rate by demographic",
          "Alternative assessment usage %"
        ],
        "owner_required": true,
        "review_default_days": 60
      },
      "toolkit_references": "Impact Explorer, Weighing Options"
    },
    {
      "scenario_id": "L2-S4",
      "title": "ER Triage Model",
      "prompt": "A new predictive analytics model for emergency department (ED) triage is revolutionizing how hospitals handle wait times, significantly reducing them. However, it seems that patients with less extensive medical histories aren't ranking as high in this system. How would you handle this?",
      "choices": {
        "A": "Continue implementing the model, but include a doctor override functionality.",
        "B": "Impose penalties for model uncertainty to enhance decision-making safety by promoting caution with limited historical data.",
        "C": "Set aside 'equity slots' in the queue to make sure that underrepresented individuals or groups have fair access."
      },
      "toolkit_cues": "Where is data missing and how does it bias priority? Who can override and how?",
      "p3_cues": "People (care outcomes), Planet (compute), Parity (patients with thin histories).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": [
          "Conduct bias audit on triage model",
          "Establish override protocols and documentation",
          "Create equity monitoring system"
        ],
        "metrics": [
          "Triage accuracy by patient history",
          "Override usage rate",
          "Equity slot utilization"
        ],
        "owner_required": true,
        "review_default_days": 30
      },
      "toolkit_references": "Future Story, Ethics Frame"
    },
    {
      "scenario_id": "L2-S5",
      "title": "Patrol Maps",
      "prompt": "A police resource tool directs additional patrols to crime 'hot spots,' creating a potential cycle of escalating tensions and safety concerns. How would you address this?",
      "choices": {
        "A": "Allocate funding for community initiatives and enforce transparent public audits.",
        "B": "Implement randomized block trials to assess effectiveness and gather data.",
        "C": "Prioritize investment in community safety programs as alternatives to traditional policing."
      },
      "toolkit_cues": "Is our process fair even if outcomes improve? What alternatives reduce surveillance load?",
      "p3_cues": "People (chilling effects), Planet (patrol miles), Parity (over-policing hot spots).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": [
          "Conduct community impact assessment",
          "Establish transparent decision-making process",
          "Create community advisory board"
        ],
        "metrics": [
          "Crime reduction in hot spots",
          "Community trust score",
          "Surveillance distribution"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Values Explainer Cards, Weighing Options"
    }
  ]
}
